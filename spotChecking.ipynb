{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Primeiramente são importadas as bibliotecass\n",
    "nescessárias, sendo elas:\n",
    " - pandas: para leitura dos dados da base de dados\n",
    " - sklearn model_selection: para seleção dos modelos,   neste caso utiliza-se o k-fold apenas\n",
    " \n",
    "    As demais são os métodos de regressão escolhidos:\n",
    " - Regressão Linear\n",
    " - Elastic Net\n",
    " - Arvore de Decisão (Regressão)\n",
    " - Floresta Aleatória (Regressão)\n",
    " - Boosting de gradiente (Regressão)\n",
    " - Support Vector (Regressão)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então realiza-se a leitura da base de dados contida no arquivo 'Analise Geral Normalizada.xlsx' e seus dados são divididos entre:\n",
    "- X : dados de entrada da função.\n",
    "- Y : valor a ser predito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Analise Geral Normalizada.xlsx\")\n",
    "array = df.values\n",
    "X = array[:,1:23]\n",
    "Y = array[:,23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Cria-se o modelo k-fold utilizando 12 folds (a\n",
    "partir de 12 folds não houve melhoria consideravel nos valores de acurácia nas saídas, e se tornam bastante custosos a partir deste ponto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "kfold = model_selection.KFold(n_splits=12, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criam-se os modelos de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearReg = LinearRegression()\n",
    "elastic = ElasticNet()\n",
    "tree = DecisionTreeRegressor()\n",
    "forest = RandomForestRegressor()\n",
    "boosting = GradientBoostingRegressor()\n",
    "supportVector = SVR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executa o cross validation dos K-folds nos modelos de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [['Linear Regression:', model_selection.cross_val_score(linearReg, X, Y, cv=kfold)],\n",
    "           ['Elastic Net:', model_selection.cross_val_score(elastic, X, Y, cv=kfold)],\n",
    "           ['Decision Tree:', model_selection.cross_val_score(tree, X, Y, cv=kfold)],\n",
    "           ['Random Forest:', model_selection.cross_val_score(forest, X, Y, cv=kfold)],\n",
    "           ['Gradient Boosting:', model_selection.cross_val_score(boosting, X, Y, cv=kfold)],\n",
    "           ['Support Vector:', model_selection.cross_val_score(supportVector, X, Y, cv=kfold)],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analise final dos testes de cross validation, sendo apresentados os dados de acurácia média entre os diferentes modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.7775510735612521\n",
      "Elastic Net: -0.0975090779406706\n",
      "Decision Tree: 0.9163300422999762\n",
      "Random Forest: 0.9533228367451723\n",
      "Gradient Boosting: 0.9486519903018733\n",
      "Support Vector: 0.6662319997294802\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result[0], result[1].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram encontrados melhores resultados nos casos de Florestas Aleatória, Boosting de Gradiente e Árvore de Decisão"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
